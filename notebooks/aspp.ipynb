{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glasses.models.segmentation.unet import DownLayer, UpLayer, ConvBnAct, UNetDecoder, UNetEncoder\n",
    "from glasses.models.base import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, atrous_rates):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, 3, padding=atrous_rates[0], dilation=atrous_rates[0])\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, 3, padding=atrous_rates[1], dilation=atrous_rates[1])\n",
    "        self.conv4 = nn.Conv2d(in_channels, out_channels, 3, padding=atrous_rates[2], dilation=atrous_rates[2])\n",
    "        self.conv5 = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.bnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.final_conv = nn.Conv2d(out_channels * 5, out_channels, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1 = self.relu(self.bnorm(self.conv1(x)))\n",
    "        out2 = self.relu(self.bnorm(self.conv2(x)))\n",
    "        out3 = self.relu(self.bnorm(self.conv3(x)))\n",
    "        out4 = self.relu(self.bnorm(self.conv4(x)))\n",
    "        out5 = F.adaptive_avg_pool2d(x, 1)\n",
    "        out5 = F.interpolate(out5, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=True)\n",
    "        out5 = self.relu(self.bnorm(self.conv5(out5)))\n",
    "        out = torch.cat([out1, out2, out3, out4, out5], dim=1)\n",
    "        out = self.relu(self.bnorm(self.final_conv(out)))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtrousBasicBlock(nn.Sequential):\n",
    "    \"\"\"Basic Block for UNet. It is composed by a double 3x3 conv.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        activation: nn.Module = partial(nn.ReLU, inplace=True),\n",
    "        atrous_rates: list = [6, 12, 18],\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            ConvBnAct(\n",
    "                in_features,\n",
    "                out_features,\n",
    "                kernel_size=3,\n",
    "                activation=activation,\n",
    "                *args,\n",
    "                **kwargs,\n",
    "            ),\n",
    "            ConvBnAct(\n",
    "                out_features,\n",
    "                out_features,\n",
    "                kernel_size=3,\n",
    "                activation=activation,\n",
    "                *args,\n",
    "                **kwargs,\n",
    "            ),\n",
    "            ASPP(out_features, out_features, atrous_rates, *args, **kwargs),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = UNetEncoder(in_channels=2, block=AtrousBasicBlock, atrous_rates=[6, 12, 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "UNetEncoder                                        [1, 1024, 16, 16]         --\n",
       "├─ModuleList: 1-1                                  --                        --\n",
       "│    └─DownLayer: 2-1                              [1, 64, 256, 256]         --\n",
       "│    │    └─Sequential: 3-1                        [1, 64, 256, 256]         178,048\n",
       "│    └─DownLayer: 2-2                              [1, 128, 128, 128]        --\n",
       "│    │    └─Sequential: 3-2                        [1, 128, 128, 128]        779,776\n",
       "│    └─DownLayer: 2-3                              [1, 256, 64, 64]          --\n",
       "│    │    └─Sequential: 3-3                        [1, 256, 64, 64]          3,116,032\n",
       "│    └─DownLayer: 2-4                              [1, 512, 32, 32]          --\n",
       "│    │    └─Sequential: 3-4                        [1, 512, 32, 32]          12,457,984\n",
       "│    └─DownLayer: 2-5                              [1, 1024, 16, 16]         --\n",
       "│    │    └─Sequential: 3-5                        [1, 1024, 16, 16]         49,819,648\n",
       "====================================================================================================\n",
       "Total params: 66,351,488\n",
       "Trainable params: 66,351,488\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 62.67\n",
       "====================================================================================================\n",
       "Input size (MB): 0.52\n",
       "Forward/backward pass size (MB): 1040.19\n",
       "Params size (MB): 265.41\n",
       "Estimated Total Size (MB): 1306.12\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "inp = torch.Tensor(1, 2, 256, 256)\n",
    "torchinfo.summary(enc, input_data=inp, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.features\n",
    "out = enc(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 16, 16])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 256, 256])\n",
      "torch.Size([1, 128, 128, 128])\n",
      "torch.Size([1, 256, 64, 64])\n",
      "torch.Size([1, 512, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "for feats in enc.features:\n",
    "    print(feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = enc.features\n",
    "residuals = features[::-1]\n",
    "dec = UNetDecoder(start_features=enc.widths[-1], lateral_widths=enc.features_widths[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.extend([None] * (len(dec.layers) - len(residuals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dec(out, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atrous_networks import unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'atrous_networks.unet' from '/home/prateek/ms_change_detection/atrous_networks/unet.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet.ASPPUNet(in_channels=2, n_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "ASPPUNet                                                [1, 1, 256, 256]          --\n",
       "├─UNetEncoder: 1-1                                      [1, 1024, 16, 16]         --\n",
       "│    └─ModuleList: 2-1                                  --                        --\n",
       "│    │    └─DownLayer: 3-1                              [1, 64, 256, 256]         141,056\n",
       "│    │    └─DownLayer: 3-2                              [1, 128, 128, 128]        632,064\n",
       "│    │    └─DownLayer: 3-3                              [1, 256, 64, 64]          2,525,696\n",
       "│    │    └─DownLayer: 3-4                              [1, 512, 32, 32]          10,097,664\n",
       "│    │    └─DownLayer: 3-5                              [1, 1024, 16, 16]         40,380,416\n",
       "├─UNetDecoder: 1-2                                      [1, 32, 256, 256]         --\n",
       "│    └─ModuleList: 2-2                                  --                        --\n",
       "│    │    └─UpLayer: 3-6                                [1, 256, 32, 32]          3,409,152\n",
       "│    │    └─UpLayer: 3-7                                [1, 128, 64, 64]          721,536\n",
       "│    │    └─UpLayer: 3-8                                [1, 64, 128, 128]         180,544\n",
       "│    │    └─UpLayer: 3-9                                [1, 32, 256, 256]         45,216\n",
       "├─Conv2d: 1-3                                           [1, 1, 256, 256]          33\n",
       "=========================================================================================================\n",
       "Total params: 58,133,377\n",
       "Trainable params: 58,133,377\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 62.94\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.52\n",
       "Forward/backward pass size (MB): 1067.97\n",
       "Params size (MB): 232.53\n",
       "Estimated Total Size (MB): 1301.03\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model, ((1, 1, 256, 256), (1, 1, 256, 256)), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free Memory: 7900.81 MB\n",
      "Total Memory: 24217.31 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prateek/anaconda3/envs/glasses/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the free and total memory\n",
    "    free_memory, total_memory = torch.cuda.mem_get_info()\n",
    "    \n",
    "    # Convert bytes to megabytes for easier reading\n",
    "    free_memory_MB = free_memory / 1024**2\n",
    "    total_memory_MB = total_memory / 1024**2\n",
    "    \n",
    "    print(f\"Free Memory: {free_memory_MB:.2f} MB\")\n",
    "    print(f\"Total Memory: {total_memory_MB:.2f} MB\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atrous_networks import unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet.ASPPUNet(in_channels=2, n_classes=1, encoder_widths=[32, 64, 128, 256], decoder_widths=[256, 128, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "ASPPUNet                                                [1, 1, 512, 512]          --\n",
       "├─UNetEncoder: 1-1                                      [1, 256, 32, 32]          --\n",
       "│    └─ModuleList: 2-1                                  --                        --\n",
       "│    │    └─DownLayer: 3-1                              [1, 32, 256, 256]         35,712\n",
       "│    │    └─DownLayer: 3-2                              [1, 64, 128, 128]         158,336\n",
       "│    │    └─DownLayer: 3-3                              [1, 128, 64, 64]          632,064\n",
       "│    │    └─DownLayer: 3-4                              [1, 256, 32, 32]          2,525,696\n",
       "├─UNetDecoder: 1-2                                      [1, 32, 512, 512]         --\n",
       "│    └─ModuleList: 2-2                                  --                        --\n",
       "│    │    └─UpLayer: 3-5                                [1, 256, 64, 64]          1,737,984\n",
       "│    │    └─UpLayer: 3-6                                [1, 128, 128, 128]        500,352\n",
       "│    │    └─UpLayer: 3-7                                [1, 64, 256, 256]         125,248\n",
       "│    │    └─UpLayer: 3-8                                [1, 32, 512, 512]         26,784\n",
       "├─Conv2d: 1-3                                           [1, 1, 512, 512]          33\n",
       "=========================================================================================================\n",
       "Total params: 5,742,209\n",
       "Trainable params: 5,742,209\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 40.59\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.52\n",
       "Forward/backward pass size (MB): 1071.64\n",
       "Params size (MB): 22.97\n",
       "Estimated Total Size (MB): 1095.14\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model, ((1, 1, 256, 256), (1, 1, 256, 256)), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glasses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
